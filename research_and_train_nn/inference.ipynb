{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from skimage import io\n",
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "from albumentations import HorizontalFlip\n",
    "\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._make_predict_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/d1/ef590ecea35843b16afa28aafb009cddb55c7f8763f4e9bd92063213e9e0/coremltools-2.0-cp36-none-manylinux1_x86_64.whl (2.7MB)\n",
      "\u001b[K    100% |################################| 2.7MB 9.4MB/s eta 0:00:01    14% |####                            | 399kB 21.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six==1.10.0 (from coremltools)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from coremltools) (1.14.5)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from coremltools) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.1.0->coremltools) (39.1.0)\n",
      "Installing collected packages: six, coremltools\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "Successfully installed coremltools-2.0 six-1.10.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.2.4 detected. Last version known to be fully compatible of Keras is 2.1.6 .\n",
      "WARNING:root:TensorFlow version 1.12.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./best_2.h5\")\n",
    "model._make_predict_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModel:\n",
    "    def __init__(self, model_path=\"./best_2.h5\"):\n",
    "        self.dlib_detector = dlib.get_frontal_face_detector()\n",
    "        self.dnn_face_detector = dlib.cnn_face_detection_model_v1(\"./dlib-models/mmod_human_face_detector.dat\")\n",
    "\n",
    "        self.model = load_model(model_path)\n",
    "        self.model._make_predict_function()\n",
    "    \n",
    "    def run(self, image):\n",
    "        print(image.shape)\n",
    "        to_nn_image = self.preprocessing(image)\n",
    "        predictions = np.argmax(self.model.predict(to_nn_image)[0])\n",
    "        return predictions\n",
    "    \n",
    "    def preprocessing(self, image):\n",
    "        eye_zone_image = self.get_eyes_zone(image)\n",
    "        to_nn_image = np.array([self.make_square(eye_zone_image)])\n",
    "        return to_nn_image\n",
    "        \n",
    "    def get_rect(self, image):\n",
    "        \"\"\"\n",
    "        image -- bgr image\n",
    "        returns: face rect\n",
    "        \"\"\"\n",
    "        rects = self.dlib_detector(image, 0)\n",
    "        if len(rects) == 1:\n",
    "            return rects[0]\n",
    "        else:\n",
    "            rects = self.dnn_face_detector(image, 0)\n",
    "            if len(rects) == 1:\n",
    "                return rects[0].rect\n",
    "            return []\n",
    "        \n",
    "    def get_eyes_zone(self, image):\n",
    "        rect = self.get_rect(image)\n",
    "        if rect == []:\n",
    "            return []\n",
    "        h, w = image.shape[:2]\n",
    "        top = np.max([0, rect.top()])\n",
    "        bottom = np.min([h, rect.bottom() - rect.height() // 2])\n",
    "        left = np.max([0, rect.left()])\n",
    "        right = np.min([w, rect.right()])\n",
    "        return image[top:bottom, left:right]\n",
    "    \n",
    "    def make_square(self, image, size=(82, 82)):\n",
    "        w, h = image.shape[:2]\n",
    "        if w > h:\n",
    "            top, bottom = 0, 0\n",
    "            left = (w - h) // 2\n",
    "            right = (w - h) - left\n",
    "        else:\n",
    "            left, right = 0, 0\n",
    "            top = (h - w) // 2\n",
    "            bottom = (h - w) - top\n",
    "        pad_image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        return cv2.resize(pad_image, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with = cv2.imread(\"./example_data_glasses/with_glasses/19.jpg\")\n",
    "image_without = cv2.imread(\"./example_data_glasses/without_glasses/16.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run(image_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
